{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f68db7b",
   "metadata": {},
   "source": [
    "# Lab | Random Forests\n",
    "For this lab, you will be using the CSV files provided in the files_for_lab folder.\n",
    "\n",
    "Instructions\n",
    "Apply the Random Forests algorithm but this time only by upscaling the data.\n",
    "Discuss the output and its impact in the bussiness scenario. Is the cost of a false positive equals to the cost of the false negative? How would you change your algorithm or data in order to maximize the return of the bussiness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53b33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd30491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = pd.read_csv('files_for_lab/numerical.csv')\n",
    "categorical = pd.read_csv('files_for_lab/categorical.csv')\n",
    "targets = pd.read_csv('files_for_lab/target.csv')\n",
    "data = pd.concat([numerical, categorical, targets], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca070ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad24508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90569\n",
       "1     4843\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.TARGET_B.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2cb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET_B']\n",
    "X = data.drop(['TARGET_B'], axis = 1)\n",
    "\n",
    "numericalX = X.select_dtypes(np.number)\n",
    "categoricalX = X.select_dtypes(object)\n",
    "\n",
    "# Note: we need to do train/test split before downsampling, and then only downsample the training set - Why?\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b2d91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reset_index(drop=True) \n",
    "y_test = y_test.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461df8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X train/ X test - numericals and categoricals transformation\n",
    "\n",
    "numericalX_train = X_train.select_dtypes(np.number)\n",
    "numericalX_test = X_test.select_dtypes(np.number)\n",
    "categoricalX_train = X_train.select_dtypes(object)\n",
    "categoricalX_test = X_test.select_dtypes(object)\n",
    "\n",
    "#we OneHotEncode the categoricals and fit on X train\n",
    "encoder = OneHotEncoder(drop='first').fit(categoricalX_train)\n",
    "encoded_cat_X_train = encoder.transform(categoricalX_train).toarray()\n",
    "encoded_cat_X_train = pd.DataFrame(encoded_cat_X_train)\n",
    "#OneHotEncoding X test\n",
    "encoded_cat_X_test = encoder.transform(categoricalX_test).toarray()\n",
    "encoded_cat_X_test = pd.DataFrame(encoded_cat_X_test)\n",
    "\n",
    "# add scaling step for numericals\n",
    "scaler = StandardScaler()\n",
    "numericalX_train_scaled = scaler.fit_transform(numericalX_train)\n",
    "numericalX_train_scaled = pd.DataFrame(numericalX_train_scaled, columns=numericalX.columns)\n",
    "numericalX_test_scaled = scaler.fit_transform(numericalX_test)\n",
    "numericalX_test_scaled = pd.DataFrame(numericalX_test_scaled,columns=numericalX.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c5a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([numericalX_train_scaled, encoded_cat_X_train], axis = 1)\n",
    "X_test = pd.concat([numericalX_test_scaled, encoded_cat_X_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "168425f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for upsampling we need to temporarily concat X_train and y_train\n",
    "trainset = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c422a9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72486, 356)\n",
      "(144972, 355)\n"
     ]
    }
   ],
   "source": [
    "# quicker way to upsample category 1:\n",
    "category_1 = trainset[trainset['TARGET_B']==1].sample(len(trainset[trainset['TARGET_B']==0]), replace = True)\n",
    "print(category_1.shape)\n",
    "\n",
    "category_0 = trainset[trainset['TARGET_B']== 0 ]\n",
    "trainset_new = pd.concat([category_0, category_1], axis = 0)\n",
    "trainset_new = trainset_new.sample(frac =1) #randomize the rows\n",
    "X_train = trainset_new.drop(['TARGET_B'], axis=1)\n",
    "y_train = trainset_new['TARGET_B']\n",
    "#data = data.reset_index(drop=True)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adf5fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_regression = X_train['TARGET_D']\n",
    "y_test_regression = X_test['TARGET_D']\n",
    "\n",
    "# Now we can remove the column target d from the set of features\n",
    "X_train = X_train.drop(['TARGET_D'], axis = 1)\n",
    "X_test = X_test.drop(['TARGET_D'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462383c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6211268382860139\n",
      "0.5822983807577425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    18083\n",
       "1     1000\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[10546,  7537],\n",
       "       [  434,   566]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20,\n",
    "                             max_samples=0.2,\n",
    "                             random_state = 42) # you can also try to optimize the bootstraping parameters\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "display(y_test.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf879681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9296364756623536"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7544/(7544+571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affa6baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03911378555798687"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "429/(10539+429)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff177736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this case, the cost of a false positive (those people who did donate, but will not get an ad)\n",
    "#is bigger than that of a false negative (people who didnt donate, but got a mail). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad27171",
   "metadata": {},
   "source": [
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(X_train, y_train)\n",
    "pred = LR.predict(X_test)\n",
    "print(LR.score(X_test, y_test))\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a86097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of a false positive is 112740.13 , the difference between what would have been spent with emails and what\n",
      " could have been donated, should donors had gotten emails.\n",
      "The cost of a false negative is 291.72 , the amount spent with emails to no-donors.\n"
     ]
    }
   ],
   "source": [
    "email =0.68\n",
    "mean_don = data['TARGET_D'][data['TARGET_D'] !=0].mean()\n",
    "false_positive = round(((7544*mean_don)-email*7544), 2)\n",
    "false_negative = round(429*email,2)\n",
    "print('The cost of a false positive is', false_positive, ', the difference between what would have been spent with emails and what\\n could have been donated, should donors had gotten emails.')\n",
    "print('The cost of a false negative is', false_negative, ', the amount spent with emails to no-donors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce2eb0a",
   "metadata": {},
   "source": [
    "### Trying Kbest to select numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "463ad9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b3b5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#because Standard scaling gives negative numbers and kbest doesnt work with negative input\n",
    "scaler = MinMaxScaler()\n",
    "numerical_scaled = scaler.fit_transform(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "760492e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_scaled\n",
    "y = targets['TARGET_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29fbfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          score    Column\n",
      "313  210.290810    RFA_2F\n",
      "305   27.516508  CARDGIFT\n",
      "110   26.474583      HVP1\n",
      "111   25.757492      HVP2\n",
      "112   21.545080      HVP3\n",
      "115   19.261394      HVP6\n",
      "113   14.874056      HVP4\n",
      "22    13.034181      ETH2\n",
      "129   12.581538       RP1\n",
      "130   11.022637       RP2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>CARDGIFT</th>\n",
       "      <th>HVP1</th>\n",
       "      <th>HVP2</th>\n",
       "      <th>HVP3</th>\n",
       "      <th>HVP6</th>\n",
       "      <th>HVP4</th>\n",
       "      <th>ETH2</th>\n",
       "      <th>RP1</th>\n",
       "      <th>RP2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column    RFA_2F  CARDGIFT      HVP1      HVP2      HVP3      HVP6      HVP4  \\\n",
       "0       0.010101  0.020202  0.070707  0.131313  0.272727  0.000000  0.020202   \n",
       "1       0.000000  0.979798  0.989899  0.989899  0.989899  0.949495  0.919192   \n",
       "2       0.020202  0.000000  0.010101  0.060606  0.181818  0.000000  0.000000   \n",
       "3       0.000000  0.101010  0.252525  0.505051  0.696970  0.101010  0.010101   \n",
       "4       0.989899  0.000000  0.010101  0.020202  0.161616  0.000000  0.252525   \n",
       "\n",
       "Column      ETH2       RP1       RP2  \n",
       "0       0.050505  0.341463  1.000000  \n",
       "1       0.919192  0.024390  0.333333  \n",
       "2       0.020202  0.341463  1.000000  \n",
       "3       0.080808  0.170732  1.000000  \n",
       "4       0.585859  0.195122  0.333333  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest = SelectKBest(chi2, k=10).fit_transform(X, y)\n",
    "# Here we choose 10 so that is easier to analyze results later, as we will see\n",
    "selected = pd.DataFrame(kbest)\n",
    "selected.head()\n",
    "\n",
    "# To check the scores\n",
    "model = SelectKBest(chi2, k=10).fit(X, y)\n",
    "df = pd.DataFrame(data = model.scores_, columns = ['score'])\n",
    "df['Column'] = numerical.columns\n",
    "print(df.sort_values(by = ['score'], ascending = False).head(10))\n",
    "\n",
    "#A bigger score suggest a better usefulness for that column\n",
    "\n",
    "\n",
    "cols = df.sort_values(by = ['score'], ascending = False).head(10)['Column']\n",
    "cols\n",
    "\n",
    "selected.columns = cols\n",
    "selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ad16fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns= selected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4df6a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical2 = numerical[num_columns] #rerun code with new numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c671cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([numerical2, categorical, targets], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5157e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data2['TARGET_B']\n",
    "X = data2.drop(['TARGET_B'], axis = 1)\n",
    "\n",
    "numericalX = X.select_dtypes(np.number)\n",
    "categoricalX = X.select_dtypes(object)\n",
    "\n",
    "# Note: we need to do train/test split before downsampling, and then only downsample the training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bc2fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reset_index(drop=True) \n",
    "y_test = y_test.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bc6489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X train/ X test - numericals and categoricals transformation\n",
    "\n",
    "numericalX_train = X_train.select_dtypes(np.number)\n",
    "numericalX_test = X_test.select_dtypes(np.number)\n",
    "categoricalX_train = X_train.select_dtypes(object)\n",
    "categoricalX_test = X_test.select_dtypes(object)\n",
    "\n",
    "#we OneHotEncode the categoricals and fit on X train\n",
    "encoder = OneHotEncoder(drop='first').fit(categoricalX_train)\n",
    "encoded_cat_X_train = encoder.transform(categoricalX_train).toarray()\n",
    "encoded_cat_X_train = pd.DataFrame(encoded_cat_X_train)\n",
    "#OneHotEncoding X test\n",
    "encoded_cat_X_test = encoder.transform(categoricalX_test).toarray()\n",
    "encoded_cat_X_test = pd.DataFrame(encoded_cat_X_test)\n",
    "\n",
    "# add scaling step for numericals\n",
    "scaler = StandardScaler()\n",
    "numericalX_train_scaled = scaler.fit_transform(numericalX_train)\n",
    "numericalX_train_scaled = pd.DataFrame(numericalX_train_scaled, columns=numericalX.columns)\n",
    "numericalX_test_scaled = scaler.transform(numericalX_test)\n",
    "numericalX_test_scaled = pd.DataFrame(numericalX_test_scaled,columns=numericalX.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a30d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([numericalX_train_scaled, encoded_cat_X_train], axis = 1)\n",
    "X_test = pd.concat([numericalX_test_scaled, encoded_cat_X_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c62bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for upsampling we need to temporarily concat X_train and y_train\n",
    "trainset = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a73556b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72486, 51)\n",
      "(144972, 50)\n"
     ]
    }
   ],
   "source": [
    "# quicker way to upsample category 1:\n",
    "category_1 = trainset[trainset['TARGET_B']==1].sample(len(trainset[trainset['TARGET_B']==0]), replace = True)\n",
    "print(category_1.shape)\n",
    "\n",
    "category_0 = trainset[trainset['TARGET_B']== 0 ]\n",
    "trainset_new = pd.concat([category_0, category_1], axis = 0)\n",
    "trainset_new = trainset_new.sample(frac =1) #randomize the rows\n",
    "X_train = trainset_new.drop(['TARGET_B'], axis=1)\n",
    "y_train = trainset_new['TARGET_B']\n",
    "#data = data.reset_index(drop=True)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5759bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_regression = X_train['TARGET_D']\n",
    "y_test_regression = X_test['TARGET_D']\n",
    "\n",
    "# Now we can remove the column target d from the set of features\n",
    "X_train = X_train.drop(['TARGET_D'], axis = 1)\n",
    "X_test = X_test.drop(['TARGET_D'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e02dbe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999586126976243\n",
      "0.9468112980139392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    18083\n",
       "1     1000\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[18064,    19],\n",
       "       [  996,     4]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Romeo run the Grid Search and found out the best ones, however, the score was too close to 1, so it is not that reliable. \n",
    "clf = RandomForestClassifier(max_depth=None,\n",
    "                             criterion = 'entropy',\n",
    "                             min_samples_split=2,\n",
    "                             min_samples_leaf =2,\n",
    "                             max_samples=0.3,\n",
    "                             random_state = 42) # you can also try to optimize the bootstraping parameters\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "display(y_test.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e57cb",
   "metadata": {},
   "source": [
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(X_train, y_train)\n",
    "pred = LR.predict(X_test)\n",
    "print(LR.score(X_test, y_test))\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22fea3",
   "metadata": {},
   "source": [
    "# Lab | Final regression model in \"Health Care for All\" Case\n",
    "Instructions\n",
    "At this point, we have created a model to predict who will make a donation and who won't. But, what about the ammount of money that each person will give? In this lab, subset those that made a donation and use that subset to create a model to predict how much money will they give.\n",
    "\n",
    "Evaluate the result of your model and estimate how much better the result are for the bussiness in comparison with the naive scenario we discuss on Monday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae5f10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data[~data['TARGET_D'].isin([0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e886613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data3.drop('TARGET_B', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efbb7e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4843, 338)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35cd5674",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data3['TARGET_D']\n",
    "X = data3.drop(['TARGET_D'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92255b",
   "metadata": {},
   "source": [
    "cat = X.select_dtypes(object)\n",
    "num = X.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113e1ec",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "num_scaled = scaler.fit_transform(num)\n",
    "num_scaled = pd.DataFrame(num_scaled,columns=num.columns)\n",
    "\n",
    "encoder = OneHotEncoder(drop='first').fit(cat)\n",
    "encoded_cat = encoder.transform(cat).toarray()\n",
    "encoded_cat = pd.DataFrame(encoded_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1aecf",
   "metadata": {},
   "source": [
    "X = pd.concat([num_scaled, encoded_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b3654b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "100bbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X train transform\n",
    "X_train_num = X_train.select_dtypes(np.number)\n",
    "X_train_cat = X_train.select_dtypes(object)\n",
    "\n",
    "encoder = OneHotEncoder(drop='first').fit(X_train_cat)\n",
    "encoded_X_train_cat = encoder.transform(X_train_cat).toarray()\n",
    "encoded_X_train_cat = pd.DataFrame(encoded_X_train_cat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "X_train_num_scaled = pd.DataFrame(X_train_num_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5eb65db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X val transform\n",
    "X_val_num = X_val.select_dtypes(np.number)\n",
    "X_val_cat = X_val.select_dtypes(object)\n",
    "\n",
    "encoder = OneHotEncoder(drop='first').fit(X_val_cat)\n",
    "encoded_X_val_cat = encoder.transform(X_val_cat).toarray()\n",
    "encoded_X_val_cat = pd.DataFrame(encoded_X_val_cat)\n",
    "\n",
    "X_val_num_scaled = scaler.transform(X_val_num)\n",
    "X_val_num_scaled = pd.DataFrame(X_val_num_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0075b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_num_scaled, encoded_X_train_cat], axis = 1)\n",
    "X_val = pd.concat([X_val_num_scaled, encoded_X_val_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b26c6275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 7)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e925813",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DecisionTreeRegressor(max_depth=3,\n",
    "                             criterion = 'mse',\n",
    "                             min_samples_split=3,\n",
    "                             min_samples_leaf =3,\n",
    "                             random_state = 42)\n",
    "model2 = LinearRegression()\n",
    "model3 = KNeighborsRegressor(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b793aaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision Tree Regressor': 0.3638929687460279, 'Linear Regression': 0.4219748233557188, 'KNN': 0.01858626224302229}\n"
     ]
    }
   ],
   "source": [
    "model_pipeline = [model1, model2, model3]\n",
    "model_names = ['Decision Tree Regressor', 'Linear Regression', 'KNN']\n",
    "scores = {}\n",
    "for model, model_name in zip(model_pipeline, model_names):\n",
    "    mean_score = np.mean(cross_val_score(model, X_train, y_train, cv=3))\n",
    "    scores[model_name] = mean_score\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8ebec0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(DecisionTreeRegressor(criterion='mse', max_depth=3, min_samples_leaf=3,\n",
       "                        min_samples_split=3, random_state=42),\n",
       "  'Decision Tree Regressor'),\n",
       " (LinearRegression(), 'Linear Regression'),\n",
       " (KNeighborsRegressor(n_neighbors=3), 'KNN')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(model_pipeline, model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "962fab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision Tree Regressor': 0.45889046913400733, 'Linear Regression': -0.0691740484932255, 'KNN': -0.022315962701981107}\n"
     ]
    }
   ],
   "source": [
    "val_scores = {}\n",
    "\n",
    "for model, model_name in zip(model_pipeline,model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    val_scores[model_name] = model.score(X_val,y_val)\n",
    "print(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5dfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
